{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijIOV5qa7nf2"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons -q\n",
        "!pip install scikit-plot -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c51-2ZTu7mJ-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics               import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFUxjzLz7sOb"
      },
      "outputs": [],
      "source": [
        "import seaborn                     as sns                           # statistical data visualization\n",
        "import tensorflow                  as tf                            # build machine learning models\n",
        "import scikitplot                  as skplt                         # data visualization and machine-learning metrics\n",
        "\n",
        "from sklearn.model_selection       import train_test_split          # split into training and test sets\n",
        "from keras.utils                   import to_categorical\n",
        "from keras.preprocessing.text      import one_hot                   # create tokens\n",
        "from keras.preprocessing.sequence  import pad_sequences             # create padding\n",
        "from sklearn.linear_model          import LogisticRegression\n",
        "from keras.models                  import Sequential\n",
        "from keras.layers                  import (Embedding,\n",
        "                                           Dense,\n",
        "                                           LSTM,\n",
        "                                           Bidirectional,\n",
        "                                           Dropout)\n",
        "\n",
        "# Decision Tree\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpPAX4h97vBz"
      },
      "outputs": [],
      "source": [
        "DATA = \"/content/gdrive/My Drive/Projekt_MIO/dataset_PL/converted-exp-PL.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq6Iuk5Q7wmD",
        "outputId": "c9f8bd5b-9cd6-494d-e474-a31e7edda97d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8L0-KzANzeG"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "u815h5qU7zeo",
        "outputId": "f141bb3a-79e9-4652-d533-b941eb5af7ab"
      },
      "outputs": [],
      "source": [
        "dfOry = pd.read_csv(DATA,sep='\\t')\n",
        "dfOry.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "PVBglqoE-MNo",
        "outputId": "5d1e3a3b-38e2-4e7f-e812-06e2eb852ad1"
      },
      "outputs": [],
      "source": [
        "categories = dfOry['statementState'].value_counts()\n",
        "\n",
        "plt.bar(categories.index, categories.values, color ='maroon',\n",
        "        width = 0.4)\n",
        "\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Number\")\n",
        "plt.title(\"Classes in dataset\")\n",
        "plt.show()\n",
        "\n",
        "# How many empty labels\n",
        "dfOry.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnn8hNHT-UYk"
      },
      "outputs": [],
      "source": [
        "# create the 'clean_text' function that receives the 'text' argument\n",
        "def clean_text(text):\n",
        "    # create variable 'word' and divide the text by words and use whitespace as delimiter\n",
        "    words = str(text).split()\n",
        "\n",
        "    # convert words to lowercase by adding space to the end of each word\n",
        "    words = [i.lower() + \" \" for i in words]\n",
        "\n",
        "    # join words into a single string, but separated by spaces\n",
        "    words = \" \".join(words)\n",
        "\n",
        "    # remove punctuation from strings, using the st.punctuation method as an argument\n",
        "    words = words.translate(words.maketrans('', '', string.punctuation))\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgc7pgKL-Vkj"
      },
      "outputs": [],
      "source": [
        "dfOry['statementText'] = dfOry['statementText'].apply(clean_text)\n",
        "dfOry['name'] = dfOry['name'].apply(clean_text)\n",
        "dfOry['party'] = dfOry['party'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LHFbG51-Yqf"
      },
      "outputs": [],
      "source": [
        "df = dfOry[['name', 'party', 'statementText', 'statementState']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OOsK_gcfxIB",
        "outputId": "c56b8938-86da-4a78-bd49-89573019fbda"
      },
      "outputs": [],
      "source": [
        "df['statementState'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKrBhUb8_O9o"
      },
      "outputs": [],
      "source": [
        "train, df_temp = train_test_split(df, test_size=0.25, stratify=df['statementState'], shuffle=True, random_state=123)\n",
        "validation, test = train_test_split(df, test_size=0.5, stratify=df['statementState'], shuffle=True, random_state=123)\n",
        "statementStateMap = { \"FALSE\": 0, \"TRUE\": 1, \"UNVERIFIABLE\": 2, \"MISLEADING\": 3 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuH-1-lCoTTI"
      },
      "outputs": [],
      "source": [
        "# converting strings to numbers of test Data\n",
        "def convertToNumbers(x_data_of_strings, y_data_of_strings, vocab_size, sent_length):\n",
        "    onehot_rep_train = [one_hot(word, vocab_size) for word in x_data_of_strings]\n",
        "    ebedded_doc_train = pad_sequences(onehot_rep_train, padding='pre', maxlen = sent_length)\n",
        "    state_train = np.array(list(map(statementStateMap.get, y_data_of_strings)))\n",
        "    return ebedded_doc_train, state_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubJdT9HNtUO"
      },
      "source": [
        "## Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9InpskxiNDgK",
        "outputId": "c693b675-8c57-4a77-b21c-69dca5edcbe6"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skjpjllERUKi"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text_data):\n",
        "    preprocessed_text = []\n",
        "\n",
        "    for sentence in tqdm(text_data):\n",
        "        sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
        "        preprocessed_text.append(' '.join(token.lower()\n",
        "                                  for token in str(sentence).split()\n",
        "                                  if token not in stopwords.words('english')))\n",
        "\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgOOH1c6NFVU",
        "outputId": "b27a3918-d5e2-4047-adf2-f594e4ed6758"
      },
      "outputs": [],
      "source": [
        "preprocessed_review = preprocess_text(df['statementText'].values)\n",
        "df['statementText'] = preprocessed_review\n",
        "df['statementText']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVwH6qLTNHUr"
      },
      "outputs": [],
      "source": [
        "# Convert the statementState column to integers using the mapping dictionary\n",
        "statementState = df['statementState'].map(statementStateMap)\n",
        "\n",
        "# Split the data\n",
        "X = df['statementText']\n",
        "y = statementState\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9pG9LKNIRP",
        "outputId": "0cbe51fa-152b-46c4-bc47-895efdf5041a"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text data\n",
        "vectorization = TfidfVectorizer(strip_accents='ascii')\n",
        "train_statement_vectorized = vectorization.fit_transform(x_train)\n",
        "test_statement_vectorized = vectorization.transform(x_test)\n",
        "\n",
        "# Train the model\n",
        "decisionTreeClassifierModel = DecisionTreeClassifier()\n",
        "decisionTreeClassifierModel.fit(train_statement_vectorized, y_train)\n",
        "\n",
        "# Evaluate the model (optional)\n",
        "predictions = decisionTreeClassifierModel.predict(test_statement_vectorized)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YZRbsBLINJNc",
        "outputId": "c4554ace-eaff-462a-aa5a-060bd4b8e523"
      },
      "outputs": [],
      "source": [
        "import graphviz\n",
        "from sklearn import tree\n",
        "\n",
        "# Get feature names from the TfidfVectorizer\n",
        "feature_names = vectorization.get_feature_names_out()\n",
        "\n",
        "# Get unique class names from the training labels\n",
        "class_names = [str(label) for label in sorted(set(y_train))]\n",
        "\n",
        "# Visualize the model\n",
        "dot_decision_tree = tree.export_graphviz(decisionTreeClassifierModel, out_file=None, feature_names=feature_names,\n",
        "                                         class_names=class_names, filled=True)\n",
        "decision_tree_plot = graphviz.Source(dot_decision_tree, format='png')\n",
        "decision_tree_plot.render(\"decision_tree\") # Save the plot as a file\n",
        "decision_tree_plot # Display the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDFviST6Nppx"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvFiZJA7NLZJ"
      },
      "outputs": [],
      "source": [
        "vectorization = TfidfVectorizer()\n",
        "x_train_fit = vectorization.fit_transform(x_train)\n",
        "x_test_fit = vectorization.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4KYNRLnNMMD",
        "outputId": "a3df0e26-5f50-443a-cca7-f80e381e306d"
      },
      "outputs": [],
      "source": [
        "logisticRegressionModel = LogisticRegression()\n",
        "logisticRegressionModel.fit(x_train_fit, y_train)\n",
        "\n",
        "# testing the model\n",
        "print(accuracy_score(y_train, logisticRegressionModel.predict(x_train_fit)))\n",
        "print(accuracy_score(y_test, logisticRegressionModel.predict(x_test_fit)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpVy9dr1NNmb"
      },
      "source": [
        "# Bidirectional LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w86a9BTFNPgA"
      },
      "outputs": [],
      "source": [
        "voc_size=10000\n",
        "embedding_vector_features=40\n",
        "sent_length = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOR72DWxNRBg"
      },
      "outputs": [],
      "source": [
        "# Define the mapping from class names to numbers (0 to 3)\n",
        "statementStateMap = {'TRUE': 0, 'FALSE': 1, 'MISLEADING': 2, 'UNVERIFIABLE': 3}\n",
        "\n",
        "# Define the function to convert strings to numbers\n",
        "def convertToNumbers2(x_data_of_strings, y_data_of_strings, vocab_size, sent_length):\n",
        "    onehot_rep_train = [one_hot(word, vocab_size) for word in x_data_of_strings]\n",
        "    ebedded_doc_train = pad_sequences(onehot_rep_train, padding='pre', maxlen=sent_length)\n",
        "    state_train = np.array(list(map(statementStateMap.get, y_data_of_strings)))\n",
        "    return ebedded_doc_train, state_train\n",
        "\n",
        "\n",
        "# Assuming 'train' and 'validation' are your DataFrames\n",
        "X_train, Y_train = convertToNumbers2(train['statementText'], train['statementState'], voc_size, sent_length)\n",
        "X_test, Y_test = convertToNumbers2(validation['statementText'], validation['statementState'], voc_size, sent_length)\n",
        "\n",
        "# Now X_train, Y_train, X_test, and Y_test are ready to be used in your model\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes=4)\n",
        "Y_test = to_categorical(Y_test, num_classes=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPDN3tP3NTGA",
        "outputId": "5ced23f4-2ca4-40bc-e57f-10fe6b01f263"
      },
      "outputs": [],
      "source": [
        "#Setting up vocabulary size\n",
        "sequentialModel1 = ()\n",
        "sequentialModel1.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
        "sequentialModel1.add(Bidirectional(LSTM(100)))  # Bidirectional LSTM layer\n",
        "sequentialModel1.add(Dropout(0.3))\n",
        "sequentialModel1.add(Dense(4, activation='softmax'))  # Use softmax for multi-class classification\n",
        "sequentialModel1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use categorical crossentropy\n",
        "print(sequentialModel1.summary())\n",
        "\n",
        "# Train the model\n",
        "sequentialModel1.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCvSBR4PaD5D",
        "outputId": "a2540789-3088-4537-e29c-b6c0bcfb2751"
      },
      "outputs": [],
      "source": [
        "pred = sequentialModel1.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "pred_class = np.argmax(pred, axis=1)\n",
        "\n",
        "# If Y_test is one-hot encoded, convert it back to class labels\n",
        "Y_test_class = np.argmax(Y_test, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(Y_test_class, pred_class)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "dopH4QpvNWJp",
        "outputId": "aad3a0b4-fae4-4f92-9ccc-b56d6723e1af"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(Y_test_class, pred_class)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"FALSE\", \"TRUE\", \"UNVERIFIABLE\", \"MISLEADING\"], yticklabels=[\"FALSE\", \"TRUE\", \"UNVERIFIABLE\", \"MISLEADING\"])\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyt7zCXMNYY0"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xFn6w35NaL8",
        "outputId": "cedcb2c6-bc2e-4d53-b1b5-65056872d7a4"
      },
      "outputs": [],
      "source": [
        "sequentialModel = Sequential()\n",
        "sequentialModel.add(Embedding(voc_size, embedding_vector_features, input_length = sent_length))\n",
        "sequentialModel.add(LSTM(100))\n",
        "# In Keras, LSTM layer LSTM(100), the number 100 represents the number of units or neurons in the LSTM layer.\n",
        "sequentialModel.add(Dense(4, activation = 'sigmoid'))\n",
        "sequentialModel.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics=['accuracy'])\n",
        "print(sequentialModel.summary())\n",
        "\n",
        "sequentialModel.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 10 , batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73HmXQSMafDV",
        "outputId": "a6536f4b-2923-4ce0-efa7-f0c0af1aaf69"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(sequentialModel.predict(X_test) > 0.5, 1,0)\n",
        "print(np.sum(y_pred) / y_pred.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8pk8dtENbfJ"
      },
      "source": [
        "# Save weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGbplqgwNdxI",
        "outputId": "6b387f86-1abe-44a1-be92-4ac6c0ea1361"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "sequentialModel1.save_weights('/content/gdrive/My Drive/Projekt_MIO/model_weights.h5')\n",
        "print(\"Model weights saved to model_weights.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
